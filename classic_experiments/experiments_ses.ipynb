{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.api import SimpleExpSmoothing\n",
    "import statsmodels\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import warnings\n",
    "import itertools\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.options.display.max_rows = 9999\n",
    "pd.options.display.max_columns = 100\n",
    "\n",
    "def show_ts(ts, forecast=None, forecast2 = None, title=\"Forecast Plot\"):\n",
    "    ax = ts.plot(label = \"Observed\", figsize=(10,3))\n",
    "    if not (forecast is None):\n",
    "        forecast.plot(ax=ax, label='Forecast')\n",
    "        plt.legend()\n",
    "    if not (forecast2 is None):\n",
    "        forecast2.plot(ax=ax, label='Forecast')\n",
    "        plt.legend()\n",
    "        \n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Messages/Second')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "durations_df = pd.read_csv(\"results/durations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_names = [\"avazu\",\"IoT\",\"wiki_de\",\"wiki_en\",\"horton\",\"retailrocket\",\"taxi\", \"alibaba\", \"google\"]\n",
    "\n",
    "sampling_rates = [\"1h\",\"15min\",\"5min\"]\n",
    "multipliers = [1,4,12]\n",
    "forecast_horizons = [12,4,1]\n",
    "\n",
    "train_test_split = 0.8\n",
    "\n",
    "for data_name in data_names:\n",
    "    for i,sampling_rate in enumerate(sampling_rates):\n",
    "        print()\n",
    "        print()\n",
    "        print(data_name, sampling_rate)\n",
    "        multiplier = multipliers[i]\n",
    "        fh = forecast_horizons[i]\n",
    "        df = pd.read_csv(\"../data/\"+data_name+\"_\"+sampling_rate+\".csv\", index_col=0, parse_dates=True)\n",
    "\n",
    "        df[\"t\"] = df.messages\n",
    "        df = df.drop([\"messages\"], axis=1)\n",
    "        df = df.dropna()\n",
    "        df = df.astype(np.int)\n",
    "\n",
    "        train = df.iloc[:int(len(df)*train_test_split)]\n",
    "        test = df.iloc[int(len(df)*train_test_split):]\n",
    "        \n",
    "        print(\"Train shape:\", train.shape)\n",
    "        print(\"Test shape:\", test.shape)\n",
    "        start_time = time.time()\n",
    "        model = SimpleExpSmoothing(train.t, initialization_method=\"estimated\").fit()\n",
    "        end_time = time.time()\n",
    "        training_duration = end_time-start_time\n",
    "\n",
    "        durations_df.loc[(durations_df.dataset == data_name) & (durations_df.sampling_rate == sampling_rate)\\\n",
    "                         , \"SimpleExpSmoothing\"] = training_duration\n",
    "        \n",
    "        try:\n",
    "            results_df = pd.read_csv(\"results/\"+ data_name + \"_\" + sampling_rate + \"_results.csv\", index_col=0, parse_dates=True)\n",
    "        except:\n",
    "            results_df = test.t.to_frame()\n",
    "            \n",
    "        results_df[\"SimpleExpSmoothing\"] = 0\n",
    "        results_df[\"SimpleExpSmoothing\"].iloc[:fh] = model.forecast(fh).values\n",
    "        i = 1\n",
    "        start_time = time.time()\n",
    "        while i < len(results_df):\n",
    "            ts = train.t.append(test.t.iloc[:i])\n",
    "            model = SimpleExpSmoothing(ts, initialization_method=\"estimated\").fit()\n",
    "\n",
    "            try:\n",
    "                results_df[\"SimpleExpSmoothing\"].iloc[i:i+fh] += model.forecast(fh).values\n",
    "            except ValueError:\n",
    "                results_df[\"SimpleExpSmoothing\"].iloc[i:] += model.forecast(len(results_df)-i).values\n",
    "            i += 1\n",
    "        end_time = time.time()\n",
    "        \n",
    "        tuning_duration = (end_time - start_time) / len(results_df)\n",
    "        durations_df.loc[(durations_df.dataset == data_name) & (durations_df.sampling_rate == sampling_rate)\\\n",
    "                         , \"SimpleExpSmoothing_tune\"] = tuning_duration\n",
    "        \n",
    "        great_divider = list(range(1,len(results_df)+1))\n",
    "        great_divider = list(map(lambda x: min(x,fh), great_divider))\n",
    "        results_df[\"SimpleExpSmoothing\"] /= great_divider\n",
    "\n",
    "        show_ts(results_df.t, results_df.SimpleExpSmoothing)\n",
    "        results_df.to_csv(\"results/\"+data_name+\"_\"+sampling_rate+\"_results.csv\")\n",
    "\n",
    "        durations_df.to_csv(\"results/durations.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
