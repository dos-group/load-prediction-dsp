{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pmdarima==1.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pmdarima as pmd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import warnings\n",
    "import itertools\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.options.display.max_rows = 9999\n",
    "pd.options.display.max_columns = 100\n",
    "\n",
    "def show_ts(ts, forecast=None, forecast2 = None, title=\"Forecast Plot\"):\n",
    "    ax = ts.plot(label = \"Observed\", figsize=(10,3))\n",
    "    if not (forecast is None):\n",
    "        forecast.plot(ax=ax, label='Forecast')\n",
    "        plt.legend()\n",
    "    if not (forecast2 is None):\n",
    "        forecast2.plot(ax=ax, label='Forecast')\n",
    "        plt.legend()\n",
    "        \n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Messages/Second')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def opt_arima(ts,m):\n",
    "    combs = [0,1]\n",
    "    best_model = None\n",
    "    best_aic = np.inf\n",
    "    for c in combs:\n",
    "        model = fit_arima(ts,c)\n",
    "        aic = model.aic()\n",
    "        if aic < best_aic:\n",
    "            best_aic = aic\n",
    "            best_model = model\n",
    "    return best_model\n",
    "\n",
    "def fit_arima(ts, d):\n",
    "    return pmd.auto_arima(ts.t, d=d, start_p=0, start_q=0,\n",
    "                             max_p=5, max_q=5, \n",
    "                             method = \"nm\", max_iter=50,\n",
    "                             error_action='ignore',\n",
    "                             seasonal=False,\n",
    "                             suppress_warnings=True,\n",
    "                             stepwise=True, trace=0)\n",
    "\n",
    "durations_df = pd.read_csv(\"results/durations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_names = [\"avazu\",\"IoT\",\"wiki_de\",\"wiki_en\",\"horton\",\"retailrocket\",\"taxi\", \"alibaba\", \"google\"]\n",
    "\n",
    "sampling_rates = [\"1h\",\"15min\",\"5min\"]\n",
    "multipliers = [1,4,12]\n",
    "forecast_horizons = [12,4,1]\n",
    "\n",
    "train_test_split = 0.8\n",
    "\n",
    "for data_name in data_names:\n",
    "    for i,sampling_rate in enumerate(sampling_rates):\n",
    "        print()\n",
    "        print()\n",
    "        print(data_name, sampling_rate)\n",
    "        multiplier = multipliers[i]\n",
    "        fh = forecast_horizons[i]\n",
    "        df = pd.read_csv(\"../data/\"+data_name+\"_\"+sampling_rate+\".csv\", index_col=0, parse_dates=True)\n",
    "\n",
    "        df[\"t\"] = df.messages\n",
    "        df = df.drop([\"messages\"], axis=1)\n",
    "        df = df.dropna()\n",
    "        df = df.astype(np.int)\n",
    "\n",
    "        train = df.iloc[:int(len(df)*train_test_split)]\n",
    "        test = df.iloc[int(len(df)*train_test_split):]\n",
    "        \n",
    "        print(\"Train shape:\", train.shape)\n",
    "        print(\"Test shape:\", test.shape)\n",
    "        start_time = time.time()\n",
    "        model = opt_arima(train, multiplier*24)\n",
    "        end_time = time.time()\n",
    "        training_duration = end_time-start_time\n",
    "\n",
    "        durations_df.loc[(durations_df.dataset == data_name) & (durations_df.sampling_rate == sampling_rate)\\\n",
    "                         , \"ARIMA_opt\"] = training_duration\n",
    "        \n",
    "        try:\n",
    "            results_df = pd.read_csv(\"results/\"+ data_name + \"_\" + sampling_rate + \"_results.csv\", index_col=0, parse_dates=True)\n",
    "        except:\n",
    "            results_df = test.t.to_frame()\n",
    "        \n",
    "        # update SARIMA every sample to newest observations.\n",
    "        results_df[\"ARIMA\"] = 0\n",
    "        results_df[\"ARIMA\"].iloc[:fh] = model.predict(fh)\n",
    "        \n",
    "        i = 1\n",
    "        start_time = time.time()\n",
    "        while i < len(results_df):\n",
    "            model.update(test.t.iloc[i-1])\n",
    "            try:\n",
    "                results_df[\"ARIMA\"].iloc[i:i+fh] += model.predict(fh)\n",
    "            except ValueError:\n",
    "                results_df[\"ARIMA\"].iloc[i:] += model.predict(len(results_df)-i)\n",
    "            i += 1\n",
    "        end_time = time.time()\n",
    "        \n",
    "        tuning_duration = (end_time - start_time) / len(results_df)\n",
    "        durations_df.loc[(durations_df.dataset == data_name) & (durations_df.sampling_rate == sampling_rate)\\\n",
    "                         , \"ARIMA_tune\"] = tuning_duration\n",
    "        \n",
    "        great_divider = list(range(1,len(results_df)+1))\n",
    "        great_divider = list(map(lambda x: min(x,fh), great_divider))\n",
    "        results_df[\"ARIMA\"] /= great_divider\n",
    "\n",
    "        show_ts(results_df.t, results_df.ARIMA)\n",
    "        \n",
    "        results_df.to_csv(\"results/\"+data_name+\"_\"+sampling_rate+\"_results.csv\")\n",
    "durations_df.to_csv(\"results/durations.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
